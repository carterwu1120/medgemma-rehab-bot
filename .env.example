HF_TOKEN=hf_replace_with_your_token
HUGGING_FACE_HUB_TOKEN=hf_replace_with_your_token

# Replace with the exact model ID you have access to.
VLLM_MODEL=google/medgemma-4b-it
VLLM_MAX_MODEL_LEN=8192
VLLM_GPU_MEMORY_UTILIZATION=0.9
VLLM_TP_SIZE=1

# Output file generated by preprocess container.
OUTPUT_JSONL=/workspace/data/rehab_train.jsonl

# Dataset sample limits for quick iteration.
MEDQUAD_LIMIT=30
CHATDOCTOR_LIMIT=70
GENMED_LIMIT=50

# Video recommendation (optional)
YOUTUBE_API_KEY=
YOUTUBE_REGION=TW
# Comma-separated YouTube channel IDs (optional but recommended)
YOUTUBE_CHANNEL_WHITELIST=
VIDEO_USE_YOUTUBE_API=1

# Backend API
BACKEND_HOST=0.0.0.0
BACKEND_PORT=9000
CORS_ORIGINS=http://localhost:3000

# Chat memory (session + long-term history)
CHAT_MEMORY_ENABLED=1
CHAT_MEMORY_BACKEND=sqlite
CHAT_MEMORY_SQLITE_PATH=artifacts/memory/chat_memory.sqlite3
CHAT_MEMORY_SESSION_LIMIT=6
CHAT_MEMORY_LONG_TERM_LIMIT=4
CHAT_MEMORY_CONTEXT_MAX_CHARS=1800
# 0 = disable rule-based follow-up resolver (recommended for natural chat).
CHAT_USE_FOLLOWUP_RESOLVER=0

# If 1, vague queries return clarification-only response (no rehab plan yet).
# Recommended 0 for natural chat flow.
RAG_CLARIFY_FIRST_ONLY=0
# hybrid = LLM generates dynamic clarification questions; template = fixed question template.
RAG_CLARIFICATION_MODE=hybrid
# natural = conversational output (recommended), structured = legacy numbered template.
RAG_RESPONSE_STYLE=natural
# Retry once if model returns very short/truncated output like "好的，我".
RAG_RETRY_SHORT_ANSWER=1
